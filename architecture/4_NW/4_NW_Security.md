

# 注意事项

- 在运输和等待过程中加密    

- 对所有的用户输入和从用户那里发来的参数进行处理以防止 XSS 和 SQL 注入。    

- 使用参数化的查询来防止 SQL 注入。    

- 使用最小权限原则。



# xss csrf

## CSRF(Cross-site request forgery)跨站请求伪造

CSRF：又称XSRF，冒充用户发起请求（在用户不知情的情况下）,
完成一些违背用户意愿的请求（如恶意发帖，删帖，改密码，发邮件等）。
很多同学会搞不明白XSS与CSRF的区别，虽然这两个关键词时常抱团出现，
但他们两个是不同维度的东西（或者说他们的目的是不一样的）。
XSS更偏向于方法论，CSRF更偏向于一种形式，只要是伪造用户发起的请求，都可成为CSRF攻击。

如何防范 CSRF 攻击？

可以注意以下几点：

- 关键操作只接受POST请求

- 验证码。
CSRF攻击的过程，往往是在用户不知情的情况下构造网络请求。
所以如果使用验证码，那么每次操作都需要用户进行互动，从而简单有效的防御了CSRF攻击。
但是如果你在一个网站作出任何举动都要输入验证码会严重影响用户体验，
所以验证码一般只出现在特殊操作里面，或者在注册时候使用。

- 检测 Referer

常见的互联网页面与页面之间是存在联系的，
比如你在www.baidu.com应该是找不到通往www.google.com的链接的，
再比如你在论坛留言，那么不管你留言后重定向到哪里去了，
之前的那个网址一定会包含留言的输入框，这个之前的网址就会保留在新页面头文件的 Referer 中
通过检查Referer的值，我们就可以判断这个请求是合法的还是非法的，
但是问题出在服务器不是任何时候都能接受到Referer的值，
所以 Referer Check 一般用于监控 CSRF 攻击的发生，而不用来抵御攻击。

- Token

    
## XSS(Cross Site Scripting)跨站脚本攻击

通过客户端脚本语言（最常见如：JavaScript）
在一个论坛发帖中发布一段恶意的JavaScript代码就是脚本注入，如果这个代码内容有请求外部服务器，那么就叫做XSS

跨站脚本（Cross-site scripting，通常简称为XSS）是一种网站应用程序的安全漏洞攻击，是代码注入的一种。
它允许恶意用户将代码注入到网页上，其他用户在观看网页时就会受到影响。这类攻击通常包含了HTML以及用户端脚本语言。


CSRF重点在请求,XSS重点在脚本



# 缓冲区溢出

缓冲区溢出是指当计算机向缓冲区内填充数据位数时超过了缓冲区本身的容量，溢出的数据覆盖在合法数据上。
理想的情况是：程序会检查数据长度，而且并不允许输入超过缓冲区长度的字符。
但是绝大多数程序都会假设数据长度总是与所分配的储存空间相匹配，这就为缓冲区溢出埋下隐患。
操作系统所使用的缓冲区，又被称为“堆栈”，在各个操作进程之间，指令会被临时储存在“堆栈”当中，“堆栈”也会出现缓冲区溢出。

# DDos攻击 Distributed Denial of Service）

DDoS 的前身是 DoS（Denail of Service），即拒绝服务攻击，指利用大量的合理请求，来占用过多的目标资源，从而使目标服务无法响应正常请求。

DDoS（Distributed Denial of Service） 则是在 DoS 的基础上，采用了分布式架构，利用多台主机同时攻击目标主机。这样，即使目标服务部署了网络防御设备，面对大量网络请求时，还是无力应对。

从攻击的原理上来看，DDoS 可以分为下面几种类型

1。耗尽带宽，

2。耗尽操作系统的资源

3。消耗应用程序的运行资源


SYN Flood 正是互联网中最经典的 DDoS 攻击方式。
原理：即客户端构造大量的 SYN 包，请求建立 TCP 连接；
而服务器收到包后，会向源 IP 发送 SYN+ACK 报文，并等待三次握手的最后一次 ACK 报文，直到超时。
这种等待状态的 TCP 连接，通常也称为半开连接。
由于连接表的大小有限，大量的半开连接就会导致连接表迅速占满，从而无法建立新的 TCP 连接。

## 解决：

找出源 IP 后，要解决 SYN 攻击的问题，只要丢掉相关的包就可以。
这时，iptables 可以帮你完成这个任务。你可以在终端一中，执行下面的 iptables 命令：

```
$ iptables -I INPUT -s 192.168.0.2 -p tcp -j REJECT/DROP
```

限制syn包的速率：

```

# 限制syn并发数为每秒1次
$ iptables -A INPUT -p tcp --syn -m limit --limit 1/s -j ACCEPT

# 限制单个IP在60秒新建立的连接数为10
$ iptables -I INPUT -p tcp --dport 80 --syn -m recent --name SYN_FLOOD --update --seconds 60 --hitcount 10 -j REJECT
```

更改配置sysctl.conf

```
$ cat /etc/sysctl.conf
net.ipv4.tcp_syncookies = 1
net.ipv4.tcp_synack_retries = 1
net.ipv4.tcp_max_syn_backlog = 1024
```

需要执行 sysctl -p 命令后，才会动态生效

TCP SYN Cookies 也是一种专门防御 SYN Flood 攻击的方法。
SYN Cookies 基于连接信息（包括源地址、源端口、目的地址、目的端口等）以及一个加密种子（如系统启动时间），
计算出一个哈希值（SHA1），这个哈希值称为 cookie。
然后，这个 cookie 就被用作序列号，来应答 SYN+ACK 包，并释放连接状态。
当客户端发送完三次握手的最后一次 ACK 后，服务器就会再次计算这个哈希值，
确认是上次返回的 SYN+ACK 的返回包，才会进入 TCP 的连接状态。

应用程序考虑识别，并尽早拒绝掉这些恶意流量，比如合理利用缓存、增加 WAF（Web Application Firewall）、使用 CDN 等等

## 总结

由于 DDoS 的分布式、大流量、难追踪等特点，目前还没有方法可以完全防御 DDoS 带来的问题，只能设法缓解这个影响。

可以购买专业的流量清洗设备和网络防火墙，在网络入口处阻断恶意流量，只保留正常流量进入数据中心的服务器中。

在 Linux 服务器中，可以通过内核调优、DPDK、XDP 等多种方法，来增大服务器的抗攻击能力，降低 DDoS 对正常服务的影响。
而在应用程序中，你可以利用各级缓存、 WAF、CDN 等方式，缓解 DDoS 对应用程序的影响。




12.怎么做过载保护的？

```
    1.过载
    “过载”一词，在海量服务的后台开发中，基本都会遇到。
    何为过载，即当前负载已经超过了系统的最大处理能力。例如，系统每秒能够处理的请求是100个，
    但实际每秒的请求量却是1000个，就可以判定系统出现了过载。

    2 过载后果
        “过载”的出现，会导致部分服务不可用，如果处置不当，极有可能引起服务完全不可用，乃至雪崩。

        我们的系统中，由于是单线程状态机的处理模式，顺序处理所有链接的缓冲区消息，当出现处理能力的下降或者请求量大幅增加，
        导致处理能力小于请求量的情况下，消息就会在系统缓冲区中堆积，造成消息处理的延迟会持续增加，在正式环境中，链接数目较多，
        系统缓冲区较大，最终会导致消息处理延迟大到不可接受的程度，最终会导致处理的都是无效消息，造成服务不可用。

        当然具体的业务需要具体的分析，把握住问题的影响，才能够做到一切尽在掌握，根据“墨菲定律”，
        通常对后果的判断不应过于乐观，谨慎行事、考虑充分才能够做到胸有成竹。

    3.过载原因
        “过载”的出现，不同系统模型的具体原因都会有所不同，例如CPU跑满，频繁读写导致IO瓶颈，内存耗尽，请求量突增等等。但究其根本原因，可以归结为两点：
        1、处理能力的下降；
        2、请求量的上升。
        只有对自身系统的有更深层和透彻的了解，才能更好地考虑如何处置问题。“头疼医头，脚疼医脚”的处理问题方式，只能解决一时之需，对症下药，才是解决问题的根本之道。
        任何问题的保护行为可以依据事件发生的阶段分为：
        1、 发生前，预防；
        2、 发生时，处置；
        3、 发生后，恢复。
        但在保护的措施中，都和业务的模型有着相关性，没有完全统一的方案，适合自己的才是最好的。

     4.过载预防
        在过载发生前的预防，就需在系统设计之初，依据具体的业务模型可以考虑预防过载的措施：
        1、 优化服务处理流程，降低处理资源消耗，提升自身处理能力；例如CPU消耗型服务，是否可以考虑优化算法，提升处理能力。
        2、 分离处理模块；将负载分担到不同的模块或者服务器；例如IO是瓶颈的服务，考虑是否可以将IO模块进行分离。
        3、 负载均衡；将请求量分流，降低单服请求量。
        4、 轻重模块分离；重要模块单独部署和处理，防止模块之间的互相影响。
        5、 前端防御；在前端控制请求频率，缓解后端压力；例如客户端可以做保护措施，控制聊天频率，点击操作失败，可以延时一段时间，
            才允许用户继续点击；前端服务发现后端出现过载问题，可选择性拒绝服务，降低后端压力。

        6、 使用缓冲区；缓冲区的使用，可以帮我们抵挡请求量的抖动，但缓冲区的使用同样也有很多技巧，
            并非越大越好。首先需要考虑内存，cpu等资源的开销，业务的模型是否需要这么大的缓冲区。
            例如缓冲区过大，处理完整个缓冲区，都需要几十秒，而前端等待超时则为几秒，那么每次处理缓冲区的内容，都是旧的，
            前端认为都是超时，服务完全不可用。另外是后端却又处理成功，会导致系统信息不对称，从而导致更为严重的问题，
            例如，在游戏中购买道具的场景，前端扣用户的钱，认为超时失败而不给用户发对应的物品，后端却又执行成功了，严重运营问题就此产生。

        7、 做好监控，及时告警；例如当CPU达到80%时，当处理请求超出一定阈值时，及时告警，做好扩容，优化等其他准备。

            当然依据业务模型的不同，还有很多预防的措施，依然是前述做到知底，才能够找出适合自身的方法。
     5.过载保护
        处理过载的方法有许多，适用于不同的业务场景，并无绝对的最优方案，合适的才是最好的，但能匹配上“合适”一词，
        是对系统整体和经验的一个考验。下面介绍一些常用的处理方案以及我们是如何做的：

        Ø 请求量阈值控制

        在系统部署上线之前，预估好系统的处理能力，限定最大同时能够处理的请求量、流量或者链接数。当请求量快接近于最大处理能力时，则告警，超过范围，则触发拒绝请求机制。由此可见对于阈值的设置是一个很关键的环节，阈值过高，依然可能导致过载，阈值过低，则又导致负载上不去。阈值的设置也会是一个不断调优的过程。该方法的优点和缺陷都很明显。

        优点：识别和处理简单；

        缺点：阈值的设定需要一定的经验，会有一定的难度，同时如果处理能力发生变化时，阈值就很难动态发生变化。

        Ø 监控系统资源

        服务器监控CPU，内存等资源的使用情况，设定阈值，超出阈值，则可以认为过载，从而触发拒绝请求机制。

        优点：使用动态的资源数据，从相对根本的原因上识别过载，而无需过多关心具体的业务处理；

        缺点：一是处理相对复杂；二是在某些场景下，资源数据的耗尽并不意味着出现过载的情况。例如服务开了较大的内存池，看起来内存资源耗尽了，实际上负载是足够的，又如现在都是多核服务器跑着多进程或者多线程的服务，单一的CPU耗尽也不能够代表服务就出现过载，但又可能产生过载，这就和具体业务有关；三是在某些场景下，出现过载的情况，也不一定会耗尽资源，例如当前所有的服务都在等待之中（可能是后端的回复或者其他），同样也不会对CPU、内存、io、网络等资源造成影响，但依然进入了过载。总体来说该方式适合的场景相对会简单点。

        Ø 检测请求到达时间

        依据请求处理的时延来判断是否过载。记录请求到达的时间戳，和处理请求结束的时间戳，得到请求到达自身服务器处理的时延，超出阈值，则可判定为超时失效，可以直接丢弃。使用独立模块读取系统缓冲区中数据，打上时间戳，存入消息缓冲区，在处理时，超过一定时延的请求，则拒绝处理，因为可以认为即使处理了也是无用的。从中可以看出时间戳很关键（为啥会单独提出这个问题，因为在后续的方案设计中，时间戳依然是解决过载问题的关键点，此处先卖个关子）。

        A、 时间戳如果使用本地读取时刻调用系统的时间函数获取，就没有考虑消息包到达系统缓冲区的时间，因此是万万不能这样做。

        B、 到可以通过ioctl调用SIOCGSTAMP的接口，获得时间戳，但这会加大系统开销，原因是每次recv完，都需要重新设置一下ioctl一次。并且不是线程安全的。

        C、 使用socket选项SO_TIMESTAMP，通过带外数据获取到数据到达系统缓冲区的时间。
```

# JWT


节省集中式令牌校验开销，实现无状态授权认证，是jwt等自包含令牌一大优势。

## 怎么验证签名是有效的呢？

jwt自校验的意思是说它的状态是自包含的(jwt令牌里头本身就有状态信息，例如用户id，也有签名算法信息)，
并不需要到DB或者其它地方去获取状态。

jwt令牌的有效性是通过签名算法+secret(也可以用公私钥)保证的，任何拿到jwt(并且有secret)的服务都可以校验。

任何没有secret的中间环节，都可以看到jwt里头信息，但是不能篡改里头的信息。

## jwt是无状态的，对于spring cloud这种分布式系统是否还需要分布式session？

传统web应用有session概念，如有需要可以集中存memcached/redis等实现分布式session。
微服务尽量无状态，一般不讲session，授权认证可用无状态jwt，也可用oauth2集中校验式令牌，
令牌存memccached/redis缓存，由网关集中验，或每个资源服务集中验，这种方式有点类似分布式session。

## 需要做SSO，用oauth + jwt怎么实现呢？

如果按oauth2的一个做法，你每个应用都应该在oauth2服务器上注册client，后面每个应用client都需要去oauth2服务器认证授权获取token，比如针对web应用可以走授权码流程，这个时候每个client获得的token其实是不同的，但是只要用户的browser在oauth2服务器上登录过，那么oauth2服务器就会暂存web session，后面只要session不过期，用户browser再次访问oauth2服务器(即便是另外一个client应用)，就不需要登录了，brower直接跳回，后台自动完成授权码的后续流程，也就是获得token。


## token和refresh_token这个具体关系是怎么样的,比如说登录成功后可以把token写到herder,这个refresh_token是调用授权服务器生成的吗 ？可以有其他处理方式吗？比如说我想自己生成一个refresh_token,但是这两者具体细节是怎样的

如果使用授权码模式且启用支持refresh token，则用户webapp经过授权认证可获取一对access token和refresh token对，后继访问api可用access token，refresh token可暂存（一般可存webapp对应db或cache，后面如果access token过期的话，webapp就可用refresh token重新获取access token。

## 大型产品生产环境中一般会选用jwt这种方案吗？还是会使用redis做缓存好呢？

具体要看场景对安全的严格要求程度，大部分场景轻量级jwt这种无状态自包含令牌就基本ok了，有些要求比较严的场景（比如金融行业），需要透明令牌+有状态集中式校验，这个时候一般可以采用redis做令牌缓存进行令牌校验操作的性能优化。




