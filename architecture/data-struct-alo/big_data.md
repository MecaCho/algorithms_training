
# 海量数据

# 总体解决办法

## 针对时间

可以采用巧妙的算法搭配合适的数据结构，如Bloom filter/Hash/bit-map/堆/数据库或倒排索引/trie树

## 针对空间

大而化小，分而治之（hash映射），各个击破
大而化小，各个击破，缩小规模，逐个解决

## 处理海量数据

1。分而治之/hash映射 + hash统计 + 堆/快速/归并排序；
2。双层桶划分
3。Bloom filter/Bitmap；
4。Trie树/数据库/倒排索引；
5。外排序；
6。分布式处理之Hadoop/Mapreduce。

# questions

## 海量数据寻找中位数

只有2G内存的pc机，在一个存有10G个整数的文件，从中找到中位数

### 外排序（排序-归并）

先将这10G的数据等分成5份存储到硬盘中，然后依次读入一份到内存里面，进行排序，然后将这5份数据进行归并得到最后的排序结果，然后找出中位数第5G大

### 堆排序（转换为求前5G大的元素）

对于10G的数据，它的中位数就是第5G个元素，按常理来说我们需要构建一个5G大小的堆，但是允许的内存只有两个G，所以我们先构建一个1G大小的大顶堆，然后求出第1G个元素（根节点），然后利用该元素构建一个新的1G大小的堆，求出第2G大的元素，依次类推，求出第5G大的元素

每次构建一个堆求第几G大的元素，都需要重新遍历完所有10G的数据，相当于要遍历5 * 10G次，这需要频繁的IO操作，需要不断的从硬盘中读取数据

### 基数排序（计数排序）

### 桶排序

假设这10G数据都是32位的无符号整数，那么每个数的值域为（0，2 ^ 32 -1）

（1）我们不可能创建2^32个桶，空间复杂度太大，所以我们创建2 ^16个桶

（2）由于我们的内存只有2G，所以一次读取2G数据，按照某种映射关系映射到对应的桶里面

（3）依次统计每个桶里面的数据，找到中位数的范围，在针对范围中的数据进行排序，找到中位数的具体位置

### 




## 海量日志数据，提取出某日访问百度次数最多的那个IP。

 IP总个数2^32 = 4G，如果单机用一个hash表来存储，光IP部分就得4G*4 = 16G，不现实

把文件按照hash(IP)%1000的方式分割成1000个小文件，相同IP的日志肯定落到了同一个文件中，

针对每一个小文件，用hash_map统计出次数最多的那个IP，得到1000个“最多”的IP，

然后在这1000个“最多”的IP中找到最大的即可。

## top K    

寻找热门查询，300万个查询字符串中统计最热门的10个查询

hashmap + 堆

##  一个大的含有50M个URL的记录，一个小的含有500个URL的记录，找出两个记录里相同的URL

首先使用包含500个url的文件创建一个hash_set

然后遍历50M的url记录,如果url在hash_set中,则输出此url并从hash_set中删除这个url

所有输出的url就是两个记录相同的url

## 有10个文件，每个文件1G，每个文件的每一行都存放的是用户的query，每个文件的query都可能重复。如何按照query的频度排序？

将所有查询进行hash(query)%10，映射成新的10个文件，大约每个1GB。

对每个文件使用hash_map统计频率并排序，然后对10个结果再归并排序。


## 从300万字符串中找到最热门的10条？    

题目:

搜索的输入信息是一个字符串，统计300万输入信息中的最热门的前10条，我们每次输入的一个字符串为不超过255byte，内存使用只有1G。请描述思想，写出算法，空间和时间复杂度。

解答:

300万个字符串最多（假设没有重复，都是最大长度）占用内存3M*1K/4=0.75G。所以可以将所有字符串都存放在内存中进行处理。

可以使用key为字符串（事实上是字符串的hash值），值为字符串出现次数的hash来统计每个每个字符串出现的次数。并用一个长度为10的数组/链表来存储目前出现次数最多的10个字符串。

这样空间和时间的复杂度都是O(n)。


# ref

https://blog.csdn.net/v_july_v/article/details/7382693
https://blog.csdn.net/v_JULY_v/article/details/6279498
https://segmentfault.com/a/1190000019890273
https://segmentfault.com/a/1190000019890273
