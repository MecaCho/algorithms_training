
# 海量数据

# 总体解决办法

## 针对时间

可以采用巧妙的算法搭配合适的数据结构，如Bloom filter/Hash/bit-map/堆/数据库或倒排索引/trie树

## 针对空间

大而化小，分而治之（hash映射），各个击破
大而化小，各个击破，缩小规模，逐个解决

## 处理海量数据

1。分而治之/hash映射 + hash统计 + 堆/快速/归并排序；
2。双层桶划分
3。Bloom filter/Bitmap；
4。Trie树/数据库/倒排索引；
5。外排序；
6。分布式处理之Hadoop/Mapreduce。

# questions

## 海量日志数据，提取出某日访问百度次数最多的那个IP。

 IP总个数2^32 = 4G，如果单机用一个hash表来存储，光IP部分就得4G*4 = 16G，不现实

把文件按照hash(IP)%1000的方式分割成1000个小文件，相同IP的日志肯定落到了同一个文件中，

针对每一个小文件，用hash_map统计出次数最多的那个IP，得到1000个“最多”的IP，

然后在这1000个“最多”的IP中找到最大的即可。

## top K    

寻找热门查询，300万个查询字符串中统计最热门的10个查询

hashmap + 堆

##  一个大的含有50M个URL的记录，一个小的含有500个URL的记录，找出两个记录里相同的URL

首先使用包含500个url的文件创建一个hash_set

然后遍历50M的url记录,如果url在hash_set中,则输出此url并从hash_set中删除这个url

所有输出的url就是两个记录相同的url

## 有10个文件，每个文件1G，每个文件的每一行都存放的是用户的query，每个文件的query都可能重复。如何按照query的频度排序？

将所有查询进行hash(query)%10，映射成新的10个文件，大约每个1GB。

对每个文件使用hash_map统计频率并排序，然后对10个结果再归并排序。


## 从300万字符串中找到最热门的10条？    

题目:

搜索的输入信息是一个字符串，统计300万输入信息中的最热门的前10条，我们每次输入的一个字符串为不超过255byte，内存使用只有1G。请描述思想，写出算法，空间和时间复杂度。

解答:

300万个字符串最多（假设没有重复，都是最大长度）占用内存3M*1K/4=0.75G。所以可以将所有字符串都存放在内存中进行处理。

可以使用key为字符串（事实上是字符串的hash值），值为字符串出现次数的hash来统计每个每个字符串出现的次数。并用一个长度为10的数组/链表来存储目前出现次数最多的10个字符串。

这样空间和时间的复杂度都是O(n)。


# ref

https://blog.csdn.net/v_july_v/article/details/7382693
https://blog.csdn.net/v_JULY_v/article/details/6279498
