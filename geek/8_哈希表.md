

总结：
一、散列表的由来？
1.散列表来源于数组，它借助散列函数对数组这种数据结构进行扩展，利用的是数组支持按照下标随机访问元素的特性。
2.需要存储在散列表中的数据我们称为键，将键转化为数组下标的方法称为散列函数，散列函数的计算结果称为散列值。
3.将数据存储在散列值对应的数组下标位置。
二、如何设计散列函数？
总结3点设计散列函数的基本要求
1.散列函数计算得到的散列值是一个非负整数。
2.若key1=key2，则hash(key1)=hash(key2)
3.若key≠key2，则hash(key1)≠hash(key2)
正是由于第3点要求，所以产生了几乎无法避免的散列冲突问题。
三、散列冲突的解放方法？
1.常用的散列冲突解决方法有2类：开放寻址法（open addressing）和链表法（chaining）
2.开放寻址法
①核心思想：如果出现散列冲突，就重新探测一个空闲位置，将其插入。
②线性探测法（Linear Probing）：
插入数据：当我们往散列表中插入数据时，如果某个数据经过散列函数之后，存储的位置已经被占用了，我们就从当前位置开始，依次往后查找，看是否有空闲位置，直到找到为止。
查找数据：我们通过散列函数求出要查找元素的键值对应的散列值，然后比较数组中下标为散列值的元素和要查找的元素是否相等，若相等，则说明就是我们要查找的元素；否则，就顺序往后依次查找。如果遍历到数组的空闲位置还未找到，就说明要查找的元素并没有在散列表中。
删除数据：为了不让查找算法失效，可以将删除的元素特殊标记为deleted，当线性探测查找的时候，遇到标记为deleted的空间，并不是停下来，而是继续往下探测。
结论：最坏时间复杂度为O(n)
③二次探测（Quadratic probing）：线性探测每次探测的步长为1，即在数组中一个一个探测，而二次探测的步长变为原来的平方。
④双重散列（Double hashing）：使用一组散列函数，直到找到空闲位置为止。
⑤线性探测法的性能描述：
用“装载因子”来表示空位多少，公式：散列表装载因子=填入表中的个数/散列表的长度。
装载因子越大，说明空闲位置越少，冲突越多，散列表的性能会下降。
3.链表法（更常用）
插入数据：当插入的时候，我们需要通过散列函数计算出对应的散列槽位，将其插入到对应的链表中即可，所以插入的时间复杂度为O(1)。
查找或删除数据：当查找、删除一个元素时，通过散列函数计算对应的槽，然后遍历链表查找或删除。对于散列比较均匀的散列函数，链表的节点个数k=n/m，其中n表示散列表中数据的个数，m表示散列表中槽的个数，所以是时间复杂度为O(k)。
四、思考
1.Word文档中单词拼写检查功能是如何实现的？
字符串占用内存大小为8字节，20万单词占用内存大小不超过20MB，所以用散列表存储20万英文词典单词，然后对每个编辑进文档的单词进行查找，若未找到，则提示拼写错误。
2.假设我们有10万条URL访问日志，如何按照访问次数给URL排序？
字符串占用内存大小为8字节，10万条URL访问日志占用内存不超过10MB，通过散列表统计url访问次数，然后用TreeMap存储散列表的元素值（作为key）和数组下标值（作为value）
3.有两个字符串数组，每个数组大约有10万条字符串，如何快速找出两个数组中相同的字符串？
分别将2个数组的字符串通过散列函数映射到散列表，散列表中的元素值为次数。注意，先存储的数组中的相同元素值不进行次数累加。最后，统计散列表中元素值大于等于2的散列值对应的字符串就是两个数组中相同的字符串。


总结：散列表（中）
面试题目：如何设计一个工业级的散列函数？
思路：
何为一个工业级的散列表？工业级的散列表应该具有哪些特性？结合学过的知识，我觉的应该有这样的要求：
1.支持快速的查询、插入、删除操作；
2.内存占用合理，不能浪费过多空间；
3.性能稳定，在极端情况下，散列表的性能也不会退化到无法接受的情况。
方案：
如何设计这样一个散列表呢？根据前面讲到的知识，我会从3个方面来考虑设计思路：
1.设计一个合适的散列函数；
2.定义装载因子阈值，并且设计动态扩容策略；
3.选择合适的散列冲突解决方法。
知识总结：
一、如何设计散列函数？
1.要尽可能让散列后的值随机且均匀分布，这样会尽可能减少散列冲突，即便冲突之后，分配到每个槽内的数据也比较均匀。
2.除此之外，散列函数的设计也不能太复杂，太复杂就会太耗时间，也会影响到散列表的性能。
3.常见的散列函数设计方法：直接寻址法、平方取中法、折叠法、随机数法等。
二、如何根据装载因子动态扩容？
1.如何设置装载因子阈值？
①可以通过设置装载因子的阈值来控制是扩容还是缩容，支持动态扩容的散列表，插入数据的时间复杂度使用摊还分析法。
②装载因子的阈值设置需要权衡时间复杂度和空间复杂度。如何权衡？如果内存空间不紧张，对执行效率要求很高，可以降低装载因子的阈值；相反，如果内存空间紧张，对执行效率要求又不高，可以增加装载因子的阈值。
2.如何避免低效扩容？分批扩容
①分批扩容的插入操作：当有新数据要插入时，我们将数据插入新的散列表，并且从老的散列表中拿出一个数据放入新散列表。每次插入都重复上面的过程。这样插入操作就变得很快了。
②分批扩容的查询操作：先查新散列表，再查老散列表。
③通过分批扩容的方式，任何情况下，插入一个数据的时间复杂度都是O(1)。
三、如何选择散列冲突解决方法？
①常见的2中方法：开放寻址法和链表法。
②大部分情况下，链表法更加普适。而且，我们还可以通过将链表法中的链表改造成其他动态查找数据结构，比如红黑树、跳表，来避免散列表时间复杂度退化成O(n)，抵御散列冲突攻击。
③但是，对于小规模数据、装载因子不高的散列表，比较适合用开放寻址法。


1.为什么散列表和链表经常放在一起使用？
2.散列表和链表如何组合起来使用？

一、为什么散列表和链表经常放在一起使用？
1.散列表的优点：支持高效的数据插入、删除和查找操作
2.散列表的缺点：不支持快速顺序遍历散列表中的数据
3.如何按照顺序快速遍历散列表的数据？只能将数据转移到数组，然后排序，最后再遍历数据。
4.我们知道散列表是动态的数据结构，需要频繁的插入和删除数据，那么每次顺序遍历之前都需要先排序，这势必会造成效率非常低下。
5.如何解决上面的问题呢？就是将散列表和链表（或跳表）结合起来使用。

二、散列表和链表如何组合起来使用？
1.LRU（Least Recently Used）缓存淘汰算法
1.1.LRU缓存淘汰算法主要操作有哪些？主要包含3个操作：
①往缓存中添加一个数据；
②从缓存中删除一个数据；
③在缓存中查找一个数据；
④总结：上面3个都涉及到查找。
1.2.如何用链表实现LRU缓存淘汰算法？
①需要维护一个按照访问时间从大到小的有序排列的链表结构。
②缓冲空间有限，当空间不足需要淘汰一个数据时直接删除链表头部的节点。
③当要缓存某个数据时，先在链表中查找这个数据。若未找到，则直接将数据放到链表的尾部。若找到，就把它移动到链表尾部。
④前面说了，LRU缓存的3个主要操作都涉及到查找，若单纯由链表实现，查找的时间复杂度很高为O(n)。若将链表和散列表结合使用，查找的时间复杂度会降低到O(1)。
1.3.如何使用散列表和链表实现LRU缓存淘汰算法？
①使用双向链表存储数据，链表中每个节点存储数据（data）、前驱指针（prev）、后继指针（next）和hnext指针（解决散列冲突的链表指针）。
②散列表通过链表法解决散列冲突，所以每个节点都会在两条链中。一条链是双向链表，另一条链是散列表中的拉链。前驱和后继指针是为了将节点串在双向链表中，hnext指针是为了将节点串在散列表的拉链中。
③LRU缓存淘汰算法的3个主要操作如何做到时间复杂度为O(1)呢？
首先，我们明确一点就是链表本身插入和删除一个节点的时间复杂度为O(1)，因为只需更改几个指针指向即可。
接着，来分析查找操作的时间复杂度。当要查找一个数据时，通过散列表可实现在O(1)时间复杂度找到该数据，再加上前面说的插入或删除的时间复杂度是O(1)，所以我们总操作的时间复杂度就是O(1)。
2.Redis有序集合
2.1.什么是有序集合？
①在有序集合中，每个成员对象有2个重要的属性，即key（键值）和score（分值）。
②不仅会通过score来查找数据，还会通过key来查找数据。
2.2.有序集合的操作有哪些？
举个例子，比如用户积分排行榜有这样一个功能：可以通过用户ID来查找积分信息，也可以通过积分区间来查找用户ID。这里用户ID就是key，积分就是score。所以，有序集合的操作如下：
①添加一个对象；
②根据键值删除一个对象；
③根据键值查找一个成员对象；
④根据分值区间查找数据，比如查找积分在[100.356]之间的成员对象；
⑤按照分值从小到大排序成员变量。
这时可以按照分值将成员对象组织成跳表结构，按照键值构建一个散列表。那么上面的所有操作都非常高效。
3.Java LinkedHashMap
和LRU缓存淘汰策略实现一模一样。支持按照插入顺序遍历数据，也支持按照访问顺序遍历数据。

三、课后思考
1.上面所讲的几个散列表和链表组合的例子里，我们都是使用双向链表。如果把双向链表改成单链表，还能否正常工作？为什么呢？
2.假设猎聘网有10万名猎头，每个猎头可以通过做任务（比如发布职位）来积累积分，然后通过积分来下载简历。假设你是猎聘网的一名工程师，如何在内存中存储这10万个猎头的ID和积分信息，让它能够支持这样几个操作：
1）根据猎头ID查收查找、删除、更新这个猎头的积分信息；
2）查找积分在某个区间的猎头ID列表；
3）查找按照积分从小到大排名在第x位到第y位之间的猎头ID列表。

1. 在删除一个元素时，虽然能 O(1) 的找到目标结点，但是要删除该结点需要拿到前一个结点的指针，遍历到前一个结点复杂度会变为 O(N），所以用双链表实现比较合适。
    （但其实硬要操作的话，单链表也是可以实现 O(1) 时间复杂度删除结点的）。
    iOS 的同学可能知道，YYMemoryCache 就是结合散列表和双向链表来实现的。

2. 以积分排序构建一个跳表，再以猎头 ID 构建一个散列表。
    1）ID 在散列表中所以可以 O(1) 查找到这个猎头；
    2）积分以跳表存储，跳表支持区间查询；
    3）这点根据目前学习的知识暂时无法实现，老师文中也提到了。


1.如何防止数据库中的用户信息被脱库？
2.你会如何存储用户密码这么重要的数据吗？仅仅 MD5 加密一下存储就够了吗？
3.在实际开发中，我们应该如何用哈希算法解决问题？
一、什么是哈希算法？
1.定义
将任意长度的二进制值串映射成固定长度的二进制值串，这个映射的规则就是哈希算法，而通过原始数据映射之后得到的二进制值串就是哈希值。
2.如何设计一个优秀的哈希算法？
①单向哈希：
从哈希值不能反向推导出哈希值（所以哈希算法也叫单向哈希算法）。
②篡改无效：
对输入敏感，哪怕原始数据只修改一个Bit，最后得到的哈希值也大不相同。
③散列冲突：
散列冲突的概率要很小，对于不同的原始数据，哈希值相同的概率非常小。
④执行效率：
哈希算法的执行效率要尽量高效，针对较长的文本，也能快速计算哈希值。
二、哈希算法的常见应用有哪些？
7个常见应用：安全加密、唯一标识、数据校验、散列函数、负载均衡、数据分片、分布式存储。
1.安全加密
①常用于加密的哈希算法：
MD5：MD5 Message-Digest Algorithm，MD5消息摘要算法
SHA：Secure Hash Algorithm，安全散列算法
DES：Data Encryption Standard，数据加密标准
AES：Advanced Encryption Standard，高级加密标准
②对用于加密的哈希算法，有两点格外重要，第一点是很难根据哈希值反向推导出原始数据，第二点是散列冲突的概率要小。
③在实际开发中要权衡破解难度和计算时间来决定究竟使用哪种加密算法。
2.唯一标识
通过哈希算法计算出数据的唯一标识，从而用于高效检索数据。
3.数据校验
利用哈希算法对输入数据敏感的特点，可以对数据取哈希值，从而高效校验数据是否被篡改过。
4.散列函数
散列函数中用到的哈希算法更加关注散列后的值能不能平均分布，以及散列函数的执行快慢。
三、思考
1.如何防止数据库中的用户信息被脱库？你会如何存储用户密码这么重要的数据吗？
①使用MD5进行加密
②字典攻击：如果用户信息被“脱库”，黑客虽然拿到的是加密之后的密文，但可以通过“猜”的方式来破解密码，这是因为，有些用户的密码太简单。
③针对字典攻击，我们可以引入一个盐（salt），跟用户密码组合在一起，增加密码的复杂度。
2.现在，区块链是一个很火的领域，它被很多人神秘化，不过其底层的实现原理并不复杂。其中，哈希算法就是它的一个非常重要的理论基础。你能讲一讲区块链使用的是哪种哈希算法吗？是为了解决什么问题而使用的呢？

课后思考：
区块链是一块块区块组成的，每个区块分为两部分：区块头和区块体。
区块头保存着 自己区块体 和 上一个区块头 的哈希值。
因为这种链式关系和哈希值的唯一性，只要区块链上任意一个区块被修改过，后面所有区块保存的哈希值就不对了。
区块链使用的是 SHA256 哈希算法，计算哈希值非常耗时，如果要篡改一个区块，就必须重新计算该区块后面所有的区块的哈希值，短时间内几乎不可能做到。


# 哈希算法在分布式系统中的应用

## 1.负载均衡
### 1.1.需求

如何实现一个会话粘滞（session sticky）的负载均衡算法？也就是说，在一次会话中的所有请求都路由到同一个服务器上。

### 1.2.解决方案
通过哈希算法对客户端IP或会话ID计算哈希值，将取得的哈希值与服务器列表的大小进行取模运算，最终得到的值就是应该被路由到的服务器编号。这样，就可以把同一个IP过来的请求都路由到同一个后端服务器上。

## 2.数据分片
### 2.1.如何统计“搜索关键词”出现的次数？
①需求描述
假如我们有1T的日志文件，这里面记录了用户的搜索关键词，我们想要快速统计出每个关键词被搜索的次数，该怎么做呢？
②问题分析
这个问题有两个难点，第一个是搜索的日子很大，没办法放到一台机器的内存中。第二个是只用一台机器来处理这么巨大的数据，处理时间会很长。
③解决方案
先对数据进行分片，然后采用多台（比如n台）机器进行处理。具体做法：从搜索记录的日志文件中依次读取每个关键词，并通过哈希函数计算该关键词的哈希值，然后跟机器的台数n取模，最终得到值就是该关键词应该被分到的机器编号，这样相同的关键词一定会被分配到同一台机器上，数据分配完成后，由多台机器并行进行统计，最后合并起来就是最终结果。
实际上，这里的处理过程也是 MapReduce 的基本设计思想。

### 2.2.如何快速判断图片是否存在图库中？
①需求描述
假设现在我们的图库中有1亿张图片，如何快速判断图片是否在图库中？基本方式是给每个图片去唯一表示（或者信息摘要），然后构建散列表。
②问题分析
很显然，在单台机器上构建散列表示行不通的，因为单台机器的内存有限，而1亿张图片构建散列表远远超过了单台机器的内存上限。
②解决方案
准备n台机器，让每台机器只维护一部分图片对应的散列表。我们每次从图库中读取一个图片，计算唯一标识，然后与机器个数n求余取模，得到的值就对应要分配的机器编号，然后将这个图片的唯一表示和图片路径发往对应的机器构建散列表。
当我们要判断一个图片是否在图库中时，我们通过同样的哈希算法，计算这个图片的唯一表示，然后与机器个数n求余取模。假设得到的值是k，那就去编号为k的机器构建的散列表中查找。
如何估算给1亿张图片构建散列表大约需要多少台机器？
散列表中每个数据单元包含两个信息，哈希值和图片文件的路径。假设我们通过 MD5 来计算哈希值，那长度就是 128 比特，也就是 16 字节。文件路径长度的上限是 256 字节，我们可以假设平均长度是 128 字节。如果我们用链表法来解决冲突，那还需要存储指针，指针只占用 8 字节。所以，散列表中每个数据单元就占用 152 字节（这里只是估算，并不准确）。
假设一台机器的内存大小为 2GB，散列表的装载因子为 0.75，那一台机器可以给大约 1000 万（2GB*0.75/152）张图片构建散列表。所以，如果要对 1 亿张图片构建索引，需要大约十几台机器。在工程中，这种估算还是很重要的，能让我们事先对需要投入的资源、资金有个大概的了解，能更好地评估解决方案的可行性。
实际上，针对这种海量数据的处理问题，我们都可以采用多机分布式处理。借助这种分片的思路，可以突破单机内存、CPU 等资源的限制。

## 3.分布式存储

### 3.1.什么是分布式存储？
 分布式存储就是将数据存储在多台机器上并提供高效的读取、写入支持。那如何决定将哪个数据放到哪个机器上呢？可以利用数据分片的思想，即通过哈希算法对数据取哈希值，然后对机器个数取模，这个最终值就是应该存储的缓存机器编号。
### 3.2.遇到的问题是什么？
如果数据持续增多，原来的机器数量已经不能满足需求，就需要增加机器，这时就麻烦了，因为所有的数据都需要重新哈希值进行再次分配。这就相当于，缓存中的数据一下子都失效了，所有的数据请求都会穿透缓存，直接去请求数据库。这样就可能发生雪崩效应，压垮数据库。
### 3.3.解决方案是什么？
①这时，需要一种方法，使得新加入一个机器后，并不需要做大量的数据搬移。那就是在分布式系统中应用非常广泛的一致性哈希算法。
②一致性哈希算法的基本思想是什么呢？为了说清楚这个问题，我们假设有k个机器，数据的哈希值范围是[0-MAX]，我们将整个范围划分成m个小区间（m远大于k），每个机器复杂m/k个小区间。当有新机器加入的时候，我们就将某几个小区间的数据，从原来的机器中搬移到新的机器中。这样，既不用全部重新哈希、搬移数据，也保持了各个机器上数据量的均衡。
