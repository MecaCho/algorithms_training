
# Redis的过期失效机制?

- 惰性清除。在访问key时，如果发现key已经过期，那么会将key删除。

- 定时清理。Redis配置项hz定义了serverCron任务的执行周期，默认每次清理时间为25ms，每次清理会依次遍历所有DB，从db随机取出20个key，如果过期就删除，如果其中有5个key过期，那么就继续对这个db进行清理，否则开始清理下一个db。

- 当执行写入命令时，如果发现内存不够，那么就会按照配置的淘汰策略清理内存，
淘汰策略主要由以下几种:    

eviction，不删除，达到内存限制时，执行写入命令时直接返回错误信息。

allkeys-lru，在所有key中，优先删除最少使用的key。（适合请求符合幂定律分布，也就是一些键访问频繁，一部分键访问较少）

allkeys-random，在所有key中，随机删除一部分key。（适合请求分布比较平均）

volatile-lru，在设置了expire的key中，优先删除最少使用的key。

volatile-random，在设置了expire的key中，随机删除一部分key。

volatile-ttl，在设置了expire的key中，优先删除剩余时间段的key。

4.0版本后增加以下两种：

volatile-lfu：从已设置过期时间的数据集(server.db[i].expires)中挑选最不经常使用的数据淘汰。

allkeys-lfu：当内存不足以容纳新写入数据时，在键空间中，移除最不经常使用的key。

## LRU

可以使用HashMap+双向链表Node来实现，每次访问元素后，将元素移动到链表尾部，当元素满了时，将链表头部的元素移除。

## LFU   

如果一个数据在最近一段时间被访问的时次数越多，那么之后被访问的概率会越大，实现是每个数据 都有一个引用计数，每次数据被访问后，引用计数加1，需要淘汰数据时，淘汰引用计数最小的数据。

在Redis的实现中， 每次key被访问后，引用计数是加一个介于0到1之间的数p，并且访问越频繁p值越大，而且在一定的时间间隔内， 如果key没有被访问，引用计数会减少

# Redis持久化方案rdb和aof的区别?

aof文件比rdb更新的频率高,优先使用aof还原数据

aof比rdb更安全也更大

rdb性能比aof好

如果两个都配了优先加载aof

AOF因为是保存了所有执行的修改命令，粒度更细，进行数据恢复时，恢复的数据更加完整，但是由于需要对所有命令执行一遍，效率比较低，同样因为是保存了所有的修改命令，同样的数据集，保存的文件会比RDB大，而且随着执行时间的增加，AOF文件可能会越来越大，所有会通过执行BGREWRITEAOF命令来重新生成AOF文件，减小文件大小。

Redis服务器故障重启后，默认恢复数据的方式首选是通过AOF文件恢复，其次是通过RDB文件恢复。

RDB是保存某一个时间点的所有键值对信息，所以恢复时可能会丢失一部分数据，但是恢复效率会比较高


# Redis的aof后台重写的触发条件?

- 可以由用户通过调用 BGREWRITEAOF手动触发    
- 服务器在AOF功能开启的情况下,会维持以下三个变量        
    记录当前AOF文件大小的变量aof_current_size
    记录最后一次AOF重写之后,AOF文件大小的变量 aof_rewrite_base_size
    增长百分比变量 aof_rewrite_perc
- 每次当 serverCron函数执行时,它都会检查以下条件是否全部满足,如果是的话,就会触发AOF重写    
    没有BGSAVE命令在进行
    没有BGREWRITEAOF在进行
    当前AOF文件大小大于server.aof_rewrite_min_size (默认值1MB)
    当前AOF文件大小和最后一次AOF重写后的大小之间的比率大于等于指定的增长百分比(默认百分比为100%)


# 简单介绍下什么是缓存击穿, 缓存穿透, 缓存雪崩? 能否介绍些应对办法?

# 解释下RESP?

Redis Serialization Protocol --- redis序列化协议

RESP是redis客户端和服务端之间使用的一种通讯协议, 特点: 实现简单,快速解析,可读性好

RESP可以用于序列化不同的数据类型,如:整型,字符串,数组..并且为错误提供专门的类型,客户端发送请求时,以字符串数组的作为待执行命令的参数,redis服务器根据不同的命令返回不同的类型

RESP是二进制安全协议,并且处理批量数据无序逐个请求处理,因此批量数据传输时,在请求参数中添加了数据长度作为前缀,传输层基于TCP协议,默认端口为6379

RESP支持五种数据类型:

简单字符串类型(Simple Strings),简单字符串以+开头

错误类型 (Errors),错误数据以-开头

整型(Integers),整数以:开头

批量字符串类型(Bulk Strings),批量字符串以$开头

数组类型(Arrays),数组以*开头

# 什么是哈希槽?    

从Redis3.0之后的版本支持redis-cluster集群,Redis-Cluster采用无中心结构,每个节点保存数据和整个集群状态,每个节点都和其他所有节点连接

结构特点:

所有的redis节点彼此互联(PING-PONG机制),内部使用二进制协议优化传输速度和带宽
节点的fail是通过集群中超过半数的节点检测失效时才生效
客户端与redis节点直连,不需要中间proxy层,客户端不需要连接集群所有节点,连接集群中任何一个可用节点即可
redis-cluster把所有的物理节点映射到[0~16383]slot上(不一定平均分配),cluster负责维护node<->slot<->value
Redis集群预分好16384个桶,当需要在Redis集群中放置一个 key-value 时,根据 CRC16(key) mod 16384的值,决定将一个key放到哪个桶中

基本思想:

一共有16384个槽,每台服务器分管其中的一部分
插入一个数据的时候,先根据CRC16算法计算key对应的值,然后用该值对16384取余数,确定将数据放到哪个槽里面
在增加的时候,之前的节点个字分出一些槽给心节点,对应的数据也一起迁出
客户端可以向任何一个Redis节点发送请求,然后由节点将请求重定向到正确的节点上

为什么要选择的槽是16384个呢？ crc16会输出16bit的结果，可以看作是一个分布在0-2^16-1之间的数，redis的作者测试发现这个数对2^{14}求模的会将key在0-2^{14-1}之间分布得很均匀，因此选了这个值。


# Redis五大对象类型和其底层实现?

# 怎么保持Redis缓存里的数据与数据库里的一致?

不管是先写MySQL数据库，再删除Redis缓存；还是先删除缓存，再写库，都有可能出现数据不一致的情况。

举一个例子：

如果删除了缓存Redis，还没有来得及写库MySQL，另一个线程就来读取，发现缓存为空，则去数据库中读取数据写入缓存，此时缓存中为脏数据。
如果先写了库，在删除缓存前，写库的线程宕机了，没有删除掉缓存，则也会出现数据不一致情况。

1.采用延时双删策略    
在写库前后都进行redis.del(key)操作，并且设定合理的超时时间。
    先删除缓存    
    再写数据库
    休眠500毫秒
    再次删除缓存

这种方案,还是有误差延时的,对于秒杀这种操作肯定是不行的! 另外,这种操作的流程是 先删除缓存,如果这时候有请求进来了

数据库还没更新操作,这时候如果量比较大可能会发生缓存穿透, 不过可能是单点穿透,这时候又对key写入了以前的值!

此时数据库更新了! 500毫秒后 再次删掉之前的key,重新穿透再缓存一次!

2.异步更新缓存(基于订阅binlog的同步机制)    

技术整体思路：(MySQL binlog增量订阅消费+消息队列+增量数据更新到redis)

读Redis：热数据基本都在Redis    
写MySQL: 增删改都是操作MySQL    
更新Redis数据：MySQ的数据操作binlog，来更新到Redis    
Redis更新

数据操作主要分为两大块：    
一个是全量(将全部数据一次写入到redis)
一个是增量（实时更新）(这里说的是增量,指的是mysql的update、insert、delate变更数据。)
读取binlog后分析 ，利用消息队列,推送更新各台的redis缓存数据。
这样一旦MySQL中产生了新的写入、更新、删除等操作，就可以把binlog相关的消息推送至Redis，Redis再根据binlog中的记录，对Redis进行更新。

其实这种机制，很类似MySQL的主从备份机制，因为MySQL的主备也是通过binlog来实现的数据一致性。

这里可以结合使用canal(阿里的一款开源框架)，通过该框架可以对MySQL的binlog进行订阅，而canal正是模仿了mysql的slave数据库的备份请求，使得Redis的数据更新达到了相同的效果。

当然，这里的消息推送工具你也可以采用别的第三方：kafka、rabbitMQ等来实现推送更新Redis!

# Redis的持久化是怎么实现的？

# 怎么防止AOF文件越来越大？

为了防止AOF文件越来越大，可以通过执行BGREWRITEAOF命令，会fork子进程出来，读取当前数据库的键值对信息，生成所需的写命令，写入新的AOF文件。

# 

