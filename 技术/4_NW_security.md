

# 注意事项

- 在运输和等待过程中加密
- 对所有的用户输入和从用户那里发来的参数进行处理以防止 XSS 和 SQL 注入。
- 使用参数化的查询来防止 SQL 注入。
- 使用最小权限原则。



1.xss csrf
```
    XSS：跨站脚本（Cross-site scripting，通常简称为XSS）是一种网站应用程序的安全漏洞攻击，是代码注入的一种。
    它允许恶意用户将代码注入到网页上，其他用户在观看网页时就会受到影响。这类攻击通常包含了HTML以及用户端脚本语言。
    CSRF:跨站请求伪造（英语：Cross-site request forgery），也被称为 one-click attack 或者 session riding，通常缩写为 CSRF 或者 XSRF，
    是一种挟制用户在当前已登录的Web应用程序上执行非本意的操作的攻击方法。


    XSS： 通过客户端脚本语言（最常见如：JavaScript）
    在一个论坛发帖中发布一段恶意的JavaScript代码就是脚本注入，如果这个代码内容有请求外部服务器，那么就叫做XSS！

    CSRF：又称XSRF，冒充用户发起请求（在用户不知情的情况下）,完成一些违背用户意愿的请求（如恶意发帖，删帖，改密码，发邮件等）。
    很多同学会搞不明白XSS与CSRF的区别，虽然这两个关键词时常抱团出现，但他们两个是不同维度的东西（或者说他们的目的是不一样的）。
    XSS更偏向于方法论，CSRF更偏向于一种形式，只要是伪造用户发起的请求，都可成为CSRF攻击。
```


12.怎么做过载保护的？

```
    1.过载
    “过载”一词，在海量服务的后台开发中，基本都会遇到。
    何为过载，即当前负载已经超过了系统的最大处理能力。例如，系统每秒能够处理的请求是100个，
    但实际每秒的请求量却是1000个，就可以判定系统出现了过载。

    2 过载后果
        “过载”的出现，会导致部分服务不可用，如果处置不当，极有可能引起服务完全不可用，乃至雪崩。

        我们的系统中，由于是单线程状态机的处理模式，顺序处理所有链接的缓冲区消息，当出现处理能力的下降或者请求量大幅增加，
        导致处理能力小于请求量的情况下，消息就会在系统缓冲区中堆积，造成消息处理的延迟会持续增加，在正式环境中，链接数目较多，
        系统缓冲区较大，最终会导致消息处理延迟大到不可接受的程度，最终会导致处理的都是无效消息，造成服务不可用。

        当然具体的业务需要具体的分析，把握住问题的影响，才能够做到一切尽在掌握，根据“墨菲定律”，
        通常对后果的判断不应过于乐观，谨慎行事、考虑充分才能够做到胸有成竹。

    3.过载原因
        “过载”的出现，不同系统模型的具体原因都会有所不同，例如CPU跑满，频繁读写导致IO瓶颈，内存耗尽，请求量突增等等。但究其根本原因，可以归结为两点：
        1、处理能力的下降；
        2、请求量的上升。
        只有对自身系统的有更深层和透彻的了解，才能更好地考虑如何处置问题。“头疼医头，脚疼医脚”的处理问题方式，只能解决一时之需，对症下药，才是解决问题的根本之道。
        任何问题的保护行为可以依据事件发生的阶段分为：
        1、 发生前，预防；
        2、 发生时，处置；
        3、 发生后，恢复。
        但在保护的措施中，都和业务的模型有着相关性，没有完全统一的方案，适合自己的才是最好的。

     4.过载预防
        在过载发生前的预防，就需在系统设计之初，依据具体的业务模型可以考虑预防过载的措施：
        1、 优化服务处理流程，降低处理资源消耗，提升自身处理能力；例如CPU消耗型服务，是否可以考虑优化算法，提升处理能力。
        2、 分离处理模块；将负载分担到不同的模块或者服务器；例如IO是瓶颈的服务，考虑是否可以将IO模块进行分离。
        3、 负载均衡；将请求量分流，降低单服请求量。
        4、 轻重模块分离；重要模块单独部署和处理，防止模块之间的互相影响。
        5、 前端防御；在前端控制请求频率，缓解后端压力；例如客户端可以做保护措施，控制聊天频率，点击操作失败，可以延时一段时间，
            才允许用户继续点击；前端服务发现后端出现过载问题，可选择性拒绝服务，降低后端压力。

        6、 使用缓冲区；缓冲区的使用，可以帮我们抵挡请求量的抖动，但缓冲区的使用同样也有很多技巧，
            并非越大越好。首先需要考虑内存，cpu等资源的开销，业务的模型是否需要这么大的缓冲区。
            例如缓冲区过大，处理完整个缓冲区，都需要几十秒，而前端等待超时则为几秒，那么每次处理缓冲区的内容，都是旧的，
            前端认为都是超时，服务完全不可用。另外是后端却又处理成功，会导致系统信息不对称，从而导致更为严重的问题，
            例如，在游戏中购买道具的场景，前端扣用户的钱，认为超时失败而不给用户发对应的物品，后端却又执行成功了，严重运营问题就此产生。

        7、 做好监控，及时告警；例如当CPU达到80%时，当处理请求超出一定阈值时，及时告警，做好扩容，优化等其他准备。

            当然依据业务模型的不同，还有很多预防的措施，依然是前述做到知底，才能够找出适合自身的方法。
     5.过载保护
        处理过载的方法有许多，适用于不同的业务场景，并无绝对的最优方案，合适的才是最好的，但能匹配上“合适”一词，
        是对系统整体和经验的一个考验。下面介绍一些常用的处理方案以及我们是如何做的：

        Ø 请求量阈值控制

        在系统部署上线之前，预估好系统的处理能力，限定最大同时能够处理的请求量、流量或者链接数。当请求量快接近于最大处理能力时，则告警，超过范围，则触发拒绝请求机制。由此可见对于阈值的设置是一个很关键的环节，阈值过高，依然可能导致过载，阈值过低，则又导致负载上不去。阈值的设置也会是一个不断调优的过程。该方法的优点和缺陷都很明显。

        优点：识别和处理简单；

        缺点：阈值的设定需要一定的经验，会有一定的难度，同时如果处理能力发生变化时，阈值就很难动态发生变化。

        Ø 监控系统资源

        服务器监控CPU，内存等资源的使用情况，设定阈值，超出阈值，则可以认为过载，从而触发拒绝请求机制。

        优点：使用动态的资源数据，从相对根本的原因上识别过载，而无需过多关心具体的业务处理；

        缺点：一是处理相对复杂；二是在某些场景下，资源数据的耗尽并不意味着出现过载的情况。例如服务开了较大的内存池，看起来内存资源耗尽了，实际上负载是足够的，又如现在都是多核服务器跑着多进程或者多线程的服务，单一的CPU耗尽也不能够代表服务就出现过载，但又可能产生过载，这就和具体业务有关；三是在某些场景下，出现过载的情况，也不一定会耗尽资源，例如当前所有的服务都在等待之中（可能是后端的回复或者其他），同样也不会对CPU、内存、io、网络等资源造成影响，但依然进入了过载。总体来说该方式适合的场景相对会简单点。

        Ø 检测请求到达时间

        依据请求处理的时延来判断是否过载。记录请求到达的时间戳，和处理请求结束的时间戳，得到请求到达自身服务器处理的时延，超出阈值，则可判定为超时失效，可以直接丢弃。使用独立模块读取系统缓冲区中数据，打上时间戳，存入消息缓冲区，在处理时，超过一定时延的请求，则拒绝处理，因为可以认为即使处理了也是无用的。从中可以看出时间戳很关键（为啥会单独提出这个问题，因为在后续的方案设计中，时间戳依然是解决过载问题的关键点，此处先卖个关子）。

        A、 时间戳如果使用本地读取时刻调用系统的时间函数获取，就没有考虑消息包到达系统缓冲区的时间，因此是万万不能这样做。

        B、 到可以通过ioctl调用SIOCGSTAMP的接口，获得时间戳，但这会加大系统开销，原因是每次recv完，都需要重新设置一下ioctl一次。并且不是线程安全的。

        C、 使用socket选项SO_TIMESTAMP，通过带外数据获取到数据到达系统缓冲区的时间。
```
